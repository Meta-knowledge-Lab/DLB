### Self-Distillation from the Last Mini-Batch (DLB)

This is a pytorch implementation for "Self-Distillation from the Last Mini-Batch for Consistency Regularization". The paper was accepted by CVPR 2022.

The paper is available at [https://arxiv.org/abs/2203.16172](https://arxiv.org/abs/2203.16172). 


Run `dlb.py` for the proposed self distillation method.



